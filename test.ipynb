{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd43097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        11\n",
      "           1       1.00      0.00      0.00         1\n",
      "           2       0.95      0.88      0.92        43\n",
      "           3       1.00      0.74      0.85        34\n",
      "           4       1.00      1.00      1.00         0\n",
      "           5       0.87      0.69      0.77       151\n",
      "           6       1.00      0.17      0.29        72\n",
      "           7       1.00      1.00      1.00         0\n",
      "           8       0.97      0.52      0.68       139\n",
      "           9       1.00      0.26      0.42        34\n",
      "          10       1.00      0.00      0.00         3\n",
      "          11       0.79      0.63      0.70       142\n",
      "          12       1.00      0.45      0.62        20\n",
      "          13       1.00      1.00      1.00         0\n",
      "          14       1.00      0.50      0.67         6\n",
      "          15       1.00      0.57      0.73        21\n",
      "          16       1.00      1.00      1.00         0\n",
      "          17       1.00      1.00      1.00         0\n",
      "          18       1.00      0.00      0.00         1\n",
      "          19       1.00      0.50      0.67         8\n",
      "          20       1.00      0.70      0.82        10\n",
      "          21       1.00      0.67      0.80        15\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       1.00      0.30      0.47        33\n",
      "          24       1.00      0.55      0.71        11\n",
      "          25       1.00      0.61      0.76        23\n",
      "          26       1.00      0.55      0.71        22\n",
      "          27       1.00      0.48      0.65        21\n",
      "          28       1.00      0.50      0.67        80\n",
      "          29       0.95      0.40      0.56        45\n",
      "          30       0.93      0.22      0.36        59\n",
      "          31       0.98      0.70      0.82       123\n",
      "          32       0.89      0.93      0.91      1123\n",
      "\n",
      "   micro avg       0.90      0.73      0.81      2252\n",
      "   macro avg       0.98      0.57      0.66      2252\n",
      "weighted avg       0.92      0.73      0.78      2252\n",
      " samples avg       0.92      0.76      0.76      2252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_labels = pd.read_csv('trainLabels.csv')[:9999]\n",
    "\n",
    "# Drop id column\n",
    "train_data = train_data.drop(columns=['id'])\n",
    "\n",
    "# Separate features\n",
    "boolean_features = []\n",
    "numerical_features = []\n",
    "hash_features = []\n",
    "\n",
    "for column in train_data.columns:\n",
    "    unique_values = train_data[column].unique()\n",
    "    num_unique_values = len(unique_values)\n",
    "    \n",
    "    if len(str(train_data[column].iloc[0])) == 44: \n",
    "        hash_features.append(column)\n",
    "        train_data[column] = train_data[column].fillna('NULL1')\n",
    "    \n",
    "    elif any(x == 'YES' for x in unique_values) and any(x == 'NO' for x in unique_values):\n",
    "        boolean_features.append(column)\n",
    "        most_frequent_value = train_data[column].mode()[0]\n",
    "        train_data[column].fillna(most_frequent_value, inplace=True)\n",
    "    \n",
    "    else:\n",
    "        numerical_features.append(column)\n",
    "        train_data[column] = train_data[column].fillna(0.0)\n",
    "\n",
    "# Prepare data\n",
    "X = train_data\n",
    "y = train_labels.drop(columns=['id'])\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('bool', OneHotEncoder(), boolean_features), \n",
    "        ('num', StandardScaler(), numerical_features), \n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "hash_transformers = []\n",
    "for column in hash_features:\n",
    "    hash_transformers.append((column, TfidfVectorizer(analyzer='char', lowercase=False), column))\n",
    "\n",
    "preprocessor.transformers.extend(hash_transformers)\n",
    "\n",
    "# Model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100))  \n",
    "])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred, zero_division=1))  # Adjusted to handle warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4881933",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data = test_data.drop(test_data.columns[0], axis=1)\n",
    "test_data.columns = train_data.columns\n",
    "for column in test_data.columns:\n",
    "    unique_values = test_data[column].unique()\n",
    "    num_unique_values = len(unique_values)\n",
    "    \n",
    "    if len(str(test_data[column].iloc[0])) == 44: \n",
    "        hash_features.append(column)\n",
    "        test_data[column] = test_data[column].fillna('NULL1')\n",
    "    \n",
    "    elif any(x == 'YES' for x in unique_values) and any(x == 'NO' for x in unique_values):\n",
    "        boolean_features.append(column)\n",
    "        most_frequent_value = test_data[column].mode()[0]\n",
    "        test_data[column].fillna(most_frequent_value, inplace=True)\n",
    "    \n",
    "    else:\n",
    "        numerical_features.append(column)\n",
    "        test_data[column] = test_data[column].fillna(0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517261d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_data)\n",
    "# Drop the 'id' column from train_labels DataFrame\n",
    "train_labels.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Create submission DataFrame using test_predictions and train_labels columns\n",
    "submission = pd.DataFrame(test_predictions, columns=train_labels.columns)\n",
    "\n",
    "id_labels = [f\"{i}_y\" for i in range(1, len(submission) + 1)]\n",
    "submission['id_label'] = id_labels\n",
    "submission = submission[['id_label'] + train_labels.columns.tolist()]\n",
    "submission.to_csv('sampleSubmission1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08065691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('sampleSubmission1.csv')\n",
    "\n",
    "# Copy the last two columns\n",
    "last_two_cols = df.iloc[:, -2:].copy()\n",
    "\n",
    "# Rename the columns\n",
    "last_two_cols.columns = ['y32', 'y33']\n",
    "\n",
    "# Add the 'id_label' column\n",
    "last_two_cols['id_label'] = [f\"{i}_y\" for i in range(1, len(last_two_cols) + 1)]\n",
    "\n",
    "# Reorder columns\n",
    "last_two_cols = last_two_cols[['id_label', 'y32', 'y33']]\n",
    "\n",
    "# Write to a new Excel file\n",
    "last_two_cols.to_excel('output1.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba026963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
